11-1 入门及架构简介

数据收集处理引擎

ETL工具

Input -> Filter(grok->date->geoip->useragent) -> Output
          
Pipeline
  - input->filter->ouput 的3阶段处理流程
  - 队列管理
  - 插件生命周期管理

Logstash Event
  - 内部流转的数据表现形式
  - 原始数据在input被转换为Event,在output event被转换为目标格式数据
  - 在配置文件中可以对Event中的属性进行增删改查

Codec(Code/Decode)  

Data->Input(decode)->Event
Event->Output(encode)->Data  

RawData->Input(codec-decode)-logstash event->Filter->Logstash event->Output(codec-encode)->Data

一个配置文件
input{
  stdin{
    codec = >line
  }
}
filter {}
output{
  stdout {
    codec => json
  }
}
================================================
11-2 Life_of_an_Event

web.log(日志文件)->File Input->Json Codec->Queue->Batcher->Filter->Output
================================================
11-3 queue简介

In Memory
  - 无法处理进程crash,机器宕机等情况,会导致数据丢失

Persistent Queue In Disk
  - 可处理进程crash等情况,保证数据不丢失
  - 保证数据至少消费一次
  - 充当缓冲区,可以替代kafaka等消息队列的作用
  
Persistent Queue
  input -> PQ(Disk) -> Filter/Output

Persistent Queue和In Memory性能之差在5%以内

PQ的基本配置
queue.type:persisted
  - 默认是memory
queue.max_bytes:4gb
  - 队列存储最大数据量  
https://www.elastic.co/guide/en/logstash/current/persistent-queues.html
================================================
11-4 线程简介

Input Thread(input->codec)
Pipeline Workder Thread(Batcher->Filter->Output)

相关配置
pipeline.workers|-w
  - pipeline 线程数,即filter_output的处理线程数,默认是cpu核数
pipeline.batch.size|-b
  - Batcher 一次批量获取的待处理文档数,默认125,可以根据输出进行调整,越大会越占用越多的heap空间,可以通过jvm.options调整
pipeline.batch.delay|-u
  - Batcher 等待时长,单位为ms

VisualVM
================================================
11-5 配置简介

logstash设置相关的配置文件(在conf文件夹中,setting files)
  - logstash.yml logstash相关配置,比如node.name,path.data,pipeline.workers,queue.type等,这其中的配置可以被命令行参数中的相关参数覆盖
  - jvm.options修改jvm的相关参数,比如修改heap size等
  
pipeline配置文件
  - 定义数据处理流程的文件,以.conf结尾

logstash.yml使用yaml语法,支持如下两种形式:
  - 层级结构
    pipeline:
      batch:
   	    size:125
		delay:50
  - 偏平结构
    pipeline.batch.size:125
    pipeline.batch.delay:50
 
常用的配置项:
node.name
  - 节点名,便于识别
path.data
  - 持久化存储数据的文件夹,默认是logstash home目录下的data
path.config
  - 设定pipeline配置文件的目录
path.log
  - 设定pipeline日志文件的目录 
pipeline.workers
  - 设定pipeline的线程数(filter+output),优化的常用项
pipeline.batch.size/delay
  - 设定批量处理数据的数目和延迟
queue.type
  - 设定队列类型,默认是memory
queue.max_bytes
  - 队列总容量,默认是1g
 
命令行配置项
--node.name
-f --path.config pipeline路径,可以是文件或者文件夹
--path.setting logstash 配置文件夹路径,其中要包含 logstash.yml
-e --config.string指明pipeline内容,多用于测试
-w --pipeline.workers
-b --pipeline.batch.size
--path.data
--debug
-t --config.test_and_exit 检查配置文件语法是否正确
 
logstash配置方式建议
  - 线上环境推荐采用配置文件的方式来设定logstash的相关配置,这样可以减少犯错的机会,而且文件便于进行版本化管理
  - 命令行形式多用来进行快速的配置测试,验证,检查等
================================================
11-6 多实例运行

bin/logstash --path.settings instance1
bin/logstash --path.settings instance2
不同instance中修改logstash.yml,自定义path.data,确保其不相同即可
================================================
11-7 pipeline配置简介

用于配置input,filter,output插件
input{}
filter{}
output{}

pipeline配置语法

主要有如下的数值类型:
布尔类型 Boolean
  - isFailed => true
数值类型 Number
  - port => 33
字符串类型 String
  - name => "Hello world"

数组 Array/List
  - users => [{id => 1,name => bob},{id => 2,name => jane}]
  - path => ["/var/log/messages","/var/log/*.log"]

哈希类型 Hash
  match => {
    "field1" => "value1"
    "field2" => "value2"
  }

在配置中可以引用Logstash Event的属性(字段),主要有如下两种方式:
  - 直接引用字段值
  - 在字符串中以sprintf方式引用


直接引用字段值 Field Referenc
  - 使用[]即可,嵌套字段写多层[]即可

{
  "ip":"192.168.23.44",
  "request":"/index.html",
  "ua":{
    "os":"windows7"
  }  
}
...
if[request] =~ "index" {}
...
...
if[ua][os] =~ "windows" {}
...

字符串中引用字段值sprintf
  - 使用 %{}来实现
{
  "ip":"192.168.23.44",
  "request":"/index.html",
  "ua":{
    "os":"windows7"
  }  
}
...
req => "request is %{request}"
...
...
ua => "ua is %{[ua][os]}"
...

支持条件判断语法,从而扩展了配置的多样性,主要格式如下:
if EXPRESSION {
  ...
} else if EXPRESSION {
  ...
} else {
  ...
}

表达式主要包含如下的操作符:
  - 比较: ==,!=,<,>,<=,>=
  - 正则是否匹配: =~,!~
  - 包含(字符串或者数组):in,not in
  - 布尔操作符: and,or,nand,xor,!
  - 分组操作符:()

例子
if [action]=="login" {}
if [loglevel]=="ERROR" and [deployment] == "production" {}
if [foo] in [foobar] {}
if [foo] in "foo" {}
if "hello" in [greeting] {}
if [foo] in ["hello","world","foo"] {}
if !("foo" in ["hello","world"]) {}
if "_grokparsefailure" not in [tags] {}


